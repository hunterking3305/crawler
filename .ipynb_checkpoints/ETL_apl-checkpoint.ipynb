{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#抓取新聞連結\n",
    "def getlink(script):\n",
    "    arry = [] \n",
    "    global count\n",
    "    global pkcount \n",
    "    apl = 'apl'\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    for a_tag in soup.select('#result h2 a'):\n",
    "        alink = a_tag.get('href').strip()\n",
    "        arry.append(alink)\n",
    "        for elelink in arry:\n",
    "            num = str(pkcount)\n",
    "            if pkcount < 10:\n",
    "                num = str(0) * 4 + num\n",
    "            elif pkcount < 100:     \n",
    "                num = str(0) * 3 + num\n",
    "            elif pkcount < 1000:     \n",
    "                num = str(0) * 2 + num\n",
    "            elif pkcount < 10000:     \n",
    "                num = str(0) * 1 + num\n",
    "            pk = apl + num\n",
    "        links = {'link':alink,'area':area,'page':page,'count':count,'pk':pk}\n",
    "        linkary.append(links)\n",
    "        count += 1\n",
    "        pkcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import *\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "#12個行政區['中正區','大同區','中山區','松山區','大安區','萬華區','信義區','士林區','北投區','內湖區','南港區','文山區']\n",
    "ary = ['中正區','大同區','中山區','松山區','大安區','萬華區','信義區','士林區','北投區','內湖區','南港區','文山區']\n",
    "links = {'link':'','area':'','page':'','count':'','pk':''}\n",
    "linkary =[]\n",
    "    \n",
    "#系統時間------------------------------\n",
    "today = date.today()\n",
    "year = today.year\n",
    "month = today.month\n",
    "day = today.day\n",
    "if month < 10:\n",
    "    month = \"0\" + str(month)\n",
    "if day < 10:\n",
    "    day = \"0\" + str(day)\n",
    "year = str(year)\n",
    "month = str(month)\n",
    "day = str(day)\n",
    "#--------------------------------------\n",
    "\n",
    "headers={\n",
    "'Origin':'http://search.appledaily.com.tw',\n",
    "'Referer':'http://search.appledaily.com.tw/appledaily/search',\n",
    "'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36' \n",
    "}\n",
    "pkcount = 1    # pkcount = 1\n",
    "for area in ary:\n",
    "    count = 1\n",
    "    for page in range(1,12):\n",
    "        payload = {\n",
    "        'searchMode':'',\n",
    "        'searchType':'text',\n",
    "        'ExtFilter':'',\n",
    "        'sorttype':'1',\n",
    "        'keyword':area,\n",
    "        'rangedate':'[20030502 TO'+year+month+day+'999:99'']',\n",
    "        'totalpage':'',\n",
    "        'page':page\n",
    "        }\n",
    "\n",
    "        res = requests.post('http://search.appledaily.com.tw/appledaily/search',headers=headers,data=payload)\n",
    "        script = res.text\n",
    "        getlink(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "data1 = pandas.DataFrame(linkary)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#輸出成CSV\n",
    "data1.to_csv('apl_link.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#讀取CSV檔\n",
    "import csv\n",
    "linkary = []\n",
    "with open('apl_link.csv',) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        linkary.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#取得人氣\n",
    "def getlike(soup): \n",
    "    if len(soup.select('.urcc a')) > 0:\n",
    "        reele = soup.select('.urcc a')[0].text\n",
    "        print soup.select('.urcc a')\n",
    "        rdrx = re.search('(\\d+)',reele)\n",
    "        likes = rdrx.group(1)\n",
    "    elif len(soup.select('.fntss a')) > 0:\n",
    "        print soup.select('.fntss a')\n",
    "        reele = soup.select('.fntss a')[0].text\n",
    "        rdrx = re.search('(\\d+)',reele)\n",
    "        likes = rdrx.group(1)\n",
    "    else:\n",
    "        likes = \"0\"\n",
    "    return likes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#抓取新聞內文\n",
    "import requests\n",
    "import time\n",
    "import re  # --\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = { \n",
    "'Origin':'http://search.appledaily.com.tw',\n",
    "'Referer':'http://search.appledaily.com.tw/appledaily/search',\n",
    "'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36'\n",
    "}\n",
    "\n",
    "for ele in linkary:\n",
    "    url = ele['link']\n",
    "    text = ''\n",
    "    while True:\n",
    "        try:\n",
    "            res = requests.get(url,headers=headers)\n",
    "            res.text\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "            \n",
    "#     try:\n",
    "        ele['title'] = soup.select('hgroup #h1')[0].text.strip()\n",
    "        ele['date'] = soup.select('.gggs time')[0]['datetime']\n",
    "        for p_tag in soup.select('#summary'):\n",
    "            text += p_tag.text.strip()\n",
    "        ele['content'] = text\n",
    "        ele['likes'] = getlike(soup)\n",
    "        \n",
    "#     except:\n",
    "#         print \"This link has some problems!\"\n",
    "#         print ele['link'], ele['area'], ele['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#新聞內文進入DataFrame\n",
    "import pandas\n",
    "data2 = pandas.DataFrame(linkary)\n",
    "\n",
    "# 移除多餘的 column\n",
    "# del data2['column name']\n",
    "apl_ok = data2.drop(data2.columns[[0]], axis=1)\n",
    "apl_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#輸出完成品\n",
    "apl_ok.to_csv('apl.csv',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
